{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1179/1179 - 8s - loss: 89595560.0000 - val_loss: 53889152.0000 - 8s/epoch - 7ms/step\n",
      "Epoch 2/150\n",
      "1179/1179 - 4s - loss: 54487048.0000 - val_loss: 52311276.0000 - 4s/epoch - 4ms/step\n",
      "Epoch 3/150\n",
      "1179/1179 - 6s - loss: 51773556.0000 - val_loss: 48780316.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 4/150\n",
      "1179/1179 - 5s - loss: 49988572.0000 - val_loss: 50231648.0000 - 5s/epoch - 5ms/step\n",
      "Epoch 5/150\n",
      "1179/1179 - 4s - loss: 48621176.0000 - val_loss: 47440340.0000 - 4s/epoch - 3ms/step\n",
      "Epoch 6/150\n",
      "1179/1179 - 4s - loss: 47463592.0000 - val_loss: 58621260.0000 - 4s/epoch - 4ms/step\n",
      "Epoch 7/150\n",
      "1179/1179 - 5s - loss: 46548412.0000 - val_loss: 45877964.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 8/150\n",
      "1179/1179 - 6s - loss: 45594644.0000 - val_loss: 47139560.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 9/150\n",
      "1179/1179 - 5s - loss: 45316960.0000 - val_loss: 48645692.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 10/150\n",
      "1179/1179 - 5s - loss: 44142084.0000 - val_loss: 46322312.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 11/150\n",
      "1179/1179 - 3s - loss: 43900456.0000 - val_loss: 44038756.0000 - 3s/epoch - 2ms/step\n",
      "Epoch 12/150\n",
      "1179/1179 - 3s - loss: 43699376.0000 - val_loss: 45629316.0000 - 3s/epoch - 2ms/step\n",
      "Epoch 13/150\n",
      "1179/1179 - 3s - loss: 42925236.0000 - val_loss: 53442372.0000 - 3s/epoch - 2ms/step\n",
      "Epoch 14/150\n",
      "1179/1179 - 3s - loss: 43881260.0000 - val_loss: 43547624.0000 - 3s/epoch - 2ms/step\n",
      "Epoch 15/150\n",
      "1179/1179 - 3s - loss: 42150396.0000 - val_loss: 43860932.0000 - 3s/epoch - 2ms/step\n",
      "Epoch 16/150\n",
      "1179/1179 - 3s - loss: 42075136.0000 - val_loss: 47688340.0000 - 3s/epoch - 2ms/step\n",
      "Epoch 17/150\n",
      "1179/1179 - 3s - loss: 41852496.0000 - val_loss: 45023952.0000 - 3s/epoch - 2ms/step\n",
      "Epoch 18/150\n",
      "1179/1179 - 3s - loss: 41159152.0000 - val_loss: 41412772.0000 - 3s/epoch - 2ms/step\n",
      "Epoch 19/150\n",
      "1179/1179 - 3s - loss: 41472016.0000 - val_loss: 42047080.0000 - 3s/epoch - 2ms/step\n",
      "Epoch 20/150\n",
      "1179/1179 - 3s - loss: 41182424.0000 - val_loss: 49351428.0000 - 3s/epoch - 2ms/step\n",
      "Epoch 21/150\n",
      "1179/1179 - 2s - loss: 41050636.0000 - val_loss: 44064588.0000 - 2s/epoch - 2ms/step\n",
      "Epoch 22/150\n",
      "1179/1179 - 3s - loss: 41182320.0000 - val_loss: 43844356.0000 - 3s/epoch - 2ms/step\n",
      "Epoch 23/150\n",
      "1179/1179 - 4s - loss: 40847284.0000 - val_loss: 40997848.0000 - 4s/epoch - 3ms/step\n",
      "Epoch 24/150\n",
      "1179/1179 - 4s - loss: 40525924.0000 - val_loss: 47989316.0000 - 4s/epoch - 4ms/step\n",
      "Epoch 25/150\n",
      "1179/1179 - 5s - loss: 40494700.0000 - val_loss: 47700892.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 26/150\n",
      "1179/1179 - 6s - loss: 39901928.0000 - val_loss: 40367324.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 27/150\n",
      "1179/1179 - 6s - loss: 40479640.0000 - val_loss: 43123708.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 28/150\n",
      "1179/1179 - 5s - loss: 40569064.0000 - val_loss: 41904276.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 29/150\n",
      "1179/1179 - 6s - loss: 40222552.0000 - val_loss: 40426480.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 30/150\n",
      "1179/1179 - 5s - loss: 40153976.0000 - val_loss: 41165576.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 31/150\n",
      "1179/1179 - 6s - loss: 39791672.0000 - val_loss: 40218164.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 32/150\n",
      "1179/1179 - 5s - loss: 39641224.0000 - val_loss: 43203624.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 33/150\n",
      "1179/1179 - 4s - loss: 39683588.0000 - val_loss: 42826032.0000 - 4s/epoch - 4ms/step\n",
      "Epoch 34/150\n",
      "1179/1179 - 4s - loss: 39774012.0000 - val_loss: 43291640.0000 - 4s/epoch - 3ms/step\n",
      "Epoch 35/150\n",
      "1179/1179 - 4s - loss: 39888820.0000 - val_loss: 43044272.0000 - 4s/epoch - 3ms/step\n",
      "Epoch 36/150\n",
      "1179/1179 - 4s - loss: 39447492.0000 - val_loss: 41381056.0000 - 4s/epoch - 3ms/step\n",
      "Epoch 37/150\n",
      "1179/1179 - 3s - loss: 39480980.0000 - val_loss: 43228676.0000 - 3s/epoch - 3ms/step\n",
      "Epoch 38/150\n",
      "1179/1179 - 4s - loss: 39522460.0000 - val_loss: 41845084.0000 - 4s/epoch - 4ms/step\n",
      "Epoch 39/150\n",
      "1179/1179 - 5s - loss: 39177012.0000 - val_loss: 41999880.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 40/150\n",
      "1179/1179 - 4s - loss: 39489108.0000 - val_loss: 42766592.0000 - 4s/epoch - 3ms/step\n",
      "Epoch 41/150\n",
      "1179/1179 - 3s - loss: 39280044.0000 - val_loss: 42054368.0000 - 3s/epoch - 3ms/step\n",
      "Epoch 42/150\n",
      "1179/1179 - 3s - loss: 39346808.0000 - val_loss: 43924752.0000 - 3s/epoch - 3ms/step\n",
      "Epoch 43/150\n",
      "1179/1179 - 3s - loss: 39026944.0000 - val_loss: 41405596.0000 - 3s/epoch - 3ms/step\n",
      "Epoch 44/150\n",
      "1179/1179 - 3s - loss: 38958580.0000 - val_loss: 43488216.0000 - 3s/epoch - 3ms/step\n",
      "Epoch 45/150\n",
      "1179/1179 - 4s - loss: 39396348.0000 - val_loss: 43185532.0000 - 4s/epoch - 3ms/step\n",
      "Epoch 46/150\n",
      "1179/1179 - 3s - loss: 38903076.0000 - val_loss: 42185132.0000 - 3s/epoch - 3ms/step\n",
      "Epoch 47/150\n",
      "1179/1179 - 3s - loss: 38611772.0000 - val_loss: 44836696.0000 - 3s/epoch - 3ms/step\n",
      "Epoch 48/150\n",
      "1179/1179 - 3s - loss: 38595248.0000 - val_loss: 43423416.0000 - 3s/epoch - 3ms/step\n",
      "Epoch 49/150\n",
      "1179/1179 - 3s - loss: 38974748.0000 - val_loss: 40651612.0000 - 3s/epoch - 3ms/step\n",
      "Epoch 50/150\n",
      "1179/1179 - 5s - loss: 39013916.0000 - val_loss: 42845960.0000 - 5s/epoch - 5ms/step\n",
      "Epoch 51/150\n",
      "1179/1179 - 5s - loss: 38880316.0000 - val_loss: 40854820.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 52/150\n",
      "1179/1179 - 4s - loss: 38634568.0000 - val_loss: 41943552.0000 - 4s/epoch - 3ms/step\n",
      "Epoch 53/150\n",
      "1179/1179 - 4s - loss: 38264380.0000 - val_loss: 46765004.0000 - 4s/epoch - 3ms/step\n",
      "Epoch 54/150\n",
      "1179/1179 - 4s - loss: 38879796.0000 - val_loss: 43859116.0000 - 4s/epoch - 3ms/step\n",
      "Epoch 55/150\n",
      "1179/1179 - 4s - loss: 38644200.0000 - val_loss: 43797908.0000 - 4s/epoch - 3ms/step\n",
      "Epoch 56/150\n",
      "1179/1179 - 4s - loss: 38635980.0000 - val_loss: 40983688.0000 - 4s/epoch - 3ms/step\n",
      "Epoch 57/150\n",
      "1179/1179 - 4s - loss: 38268268.0000 - val_loss: 42935532.0000 - 4s/epoch - 3ms/step\n",
      "Epoch 58/150\n",
      "1179/1179 - 3s - loss: 38232092.0000 - val_loss: 42419884.0000 - 3s/epoch - 3ms/step\n",
      "Epoch 59/150\n",
      "1179/1179 - 3s - loss: 39042988.0000 - val_loss: 40228164.0000 - 3s/epoch - 3ms/step\n",
      "Epoch 60/150\n",
      "1179/1179 - 4s - loss: 38350712.0000 - val_loss: 40944728.0000 - 4s/epoch - 3ms/step\n",
      "Epoch 61/150\n",
      "1179/1179 - 5s - loss: 38161484.0000 - val_loss: 40603576.0000 - 5s/epoch - 5ms/step\n",
      "Epoch 62/150\n",
      "1179/1179 - 6s - loss: 38238564.0000 - val_loss: 42079300.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 63/150\n",
      "1179/1179 - 6s - loss: 38374380.0000 - val_loss: 41558772.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 64/150\n",
      "1179/1179 - 5s - loss: 38062264.0000 - val_loss: 46886276.0000 - 5s/epoch - 5ms/step\n",
      "Epoch 65/150\n",
      "1179/1179 - 5s - loss: 38241348.0000 - val_loss: 40273272.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 66/150\n",
      "1179/1179 - 4s - loss: 38098916.0000 - val_loss: 41960452.0000 - 4s/epoch - 3ms/step\n",
      "Epoch 67/150\n",
      "1179/1179 - 4s - loss: 38026512.0000 - val_loss: 42174684.0000 - 4s/epoch - 4ms/step\n",
      "Epoch 68/150\n",
      "1179/1179 - 6s - loss: 38078556.0000 - val_loss: 45887468.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 69/150\n",
      "1179/1179 - 6s - loss: 38398180.0000 - val_loss: 43640468.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 70/150\n",
      "1179/1179 - 5s - loss: 37798056.0000 - val_loss: 40208540.0000 - 5s/epoch - 5ms/step\n",
      "Epoch 71/150\n",
      "1179/1179 - 6s - loss: 38171924.0000 - val_loss: 45123812.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 72/150\n",
      "1179/1179 - 6s - loss: 38063144.0000 - val_loss: 43930808.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 73/150\n",
      "1179/1179 - 5s - loss: 37739040.0000 - val_loss: 42708184.0000 - 5s/epoch - 5ms/step\n",
      "Epoch 74/150\n",
      "1179/1179 - 5s - loss: 37960516.0000 - val_loss: 42183236.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 75/150\n",
      "1179/1179 - 4s - loss: 37768572.0000 - val_loss: 42386628.0000 - 4s/epoch - 4ms/step\n",
      "Epoch 76/150\n",
      "1179/1179 - 6s - loss: 38099080.0000 - val_loss: 41191812.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 77/150\n",
      "1179/1179 - 5s - loss: 38148468.0000 - val_loss: 42180228.0000 - 5s/epoch - 5ms/step\n",
      "Epoch 78/150\n",
      "1179/1179 - 6s - loss: 38313316.0000 - val_loss: 40551076.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 79/150\n",
      "1179/1179 - 4s - loss: 37905232.0000 - val_loss: 40812156.0000 - 4s/epoch - 4ms/step\n",
      "Epoch 80/150\n",
      "1179/1179 - 6s - loss: 37823052.0000 - val_loss: 41591548.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 81/150\n",
      "1179/1179 - 6s - loss: 37615956.0000 - val_loss: 43302104.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 82/150\n",
      "1179/1179 - 6s - loss: 37772160.0000 - val_loss: 41677432.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 83/150\n",
      "1179/1179 - 5s - loss: 37475152.0000 - val_loss: 46183780.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 84/150\n",
      "1179/1179 - 6s - loss: 37622136.0000 - val_loss: 41096944.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 85/150\n",
      "1179/1179 - 5s - loss: 37874076.0000 - val_loss: 40615420.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 86/150\n",
      "1179/1179 - 6s - loss: 37763476.0000 - val_loss: 42040720.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 87/150\n",
      "1179/1179 - 6s - loss: 37468068.0000 - val_loss: 42570688.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 88/150\n",
      "1179/1179 - 6s - loss: 37831112.0000 - val_loss: 44674940.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 89/150\n",
      "1179/1179 - 5s - loss: 37836796.0000 - val_loss: 40847288.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 90/150\n",
      "1179/1179 - 5s - loss: 37433576.0000 - val_loss: 40991792.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 91/150\n",
      "1179/1179 - 6s - loss: 37634172.0000 - val_loss: 43736800.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 92/150\n",
      "1179/1179 - 5s - loss: 37677420.0000 - val_loss: 42458652.0000 - 5s/epoch - 5ms/step\n",
      "Epoch 93/150\n",
      "1179/1179 - 6s - loss: 37612036.0000 - val_loss: 44174764.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 94/150\n",
      "1179/1179 - 6s - loss: 37411468.0000 - val_loss: 45512840.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 95/150\n",
      "1179/1179 - 5s - loss: 37624920.0000 - val_loss: 46792804.0000 - 5s/epoch - 5ms/step\n",
      "Epoch 96/150\n",
      "1179/1179 - 6s - loss: 37677064.0000 - val_loss: 43867720.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 97/150\n",
      "1179/1179 - 5s - loss: 37472880.0000 - val_loss: 41681324.0000 - 5s/epoch - 5ms/step\n",
      "Epoch 98/150\n",
      "1179/1179 - 5s - loss: 37508408.0000 - val_loss: 42043076.0000 - 5s/epoch - 5ms/step\n",
      "Epoch 99/150\n",
      "1179/1179 - 5s - loss: 37488280.0000 - val_loss: 41952668.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 100/150\n",
      "1179/1179 - 5s - loss: 37493352.0000 - val_loss: 41751216.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 101/150\n",
      "1179/1179 - 6s - loss: 37004592.0000 - val_loss: 41866532.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 102/150\n",
      "1179/1179 - 6s - loss: 37157020.0000 - val_loss: 42701160.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 103/150\n",
      "1179/1179 - 6s - loss: 37345180.0000 - val_loss: 40982100.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 104/150\n",
      "1179/1179 - 3s - loss: 37438076.0000 - val_loss: 40571328.0000 - 3s/epoch - 3ms/step\n",
      "Epoch 105/150\n",
      "1179/1179 - 3s - loss: 37286972.0000 - val_loss: 40810084.0000 - 3s/epoch - 2ms/step\n",
      "Epoch 106/150\n",
      "1179/1179 - 5s - loss: 37214988.0000 - val_loss: 43506956.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 107/150\n",
      "1179/1179 - 5s - loss: 37513812.0000 - val_loss: 40691292.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 108/150\n",
      "1179/1179 - 6s - loss: 37851212.0000 - val_loss: 43871324.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 109/150\n",
      "1179/1179 - 6s - loss: 36945536.0000 - val_loss: 42118140.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 110/150\n",
      "1179/1179 - 4s - loss: 37540260.0000 - val_loss: 47702800.0000 - 4s/epoch - 4ms/step\n",
      "Epoch 111/150\n",
      "1179/1179 - 6s - loss: 37489644.0000 - val_loss: 39941796.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 112/150\n",
      "1179/1179 - 5s - loss: 36976304.0000 - val_loss: 40049992.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 113/150\n",
      "1179/1179 - 6s - loss: 37423012.0000 - val_loss: 41444308.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 114/150\n",
      "1179/1179 - 6s - loss: 36863272.0000 - val_loss: 41969604.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 115/150\n",
      "1179/1179 - 6s - loss: 37166452.0000 - val_loss: 41351336.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 116/150\n",
      "1179/1179 - 5s - loss: 37471120.0000 - val_loss: 44570764.0000 - 5s/epoch - 5ms/step\n",
      "Epoch 117/150\n",
      "1179/1179 - 5s - loss: 37313160.0000 - val_loss: 40337768.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 118/150\n",
      "1179/1179 - 6s - loss: 37098772.0000 - val_loss: 41563408.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 119/150\n",
      "1179/1179 - 5s - loss: 37108380.0000 - val_loss: 40239364.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 120/150\n",
      "1179/1179 - 6s - loss: 36796960.0000 - val_loss: 41503636.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 121/150\n",
      "1179/1179 - 6s - loss: 37261420.0000 - val_loss: 40377852.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 122/150\n",
      "1179/1179 - 6s - loss: 37126308.0000 - val_loss: 40740100.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 123/150\n",
      "1179/1179 - 5s - loss: 37043696.0000 - val_loss: 43892032.0000 - 5s/epoch - 5ms/step\n",
      "Epoch 124/150\n",
      "1179/1179 - 4s - loss: 37078644.0000 - val_loss: 41607560.0000 - 4s/epoch - 3ms/step\n",
      "Epoch 125/150\n",
      "1179/1179 - 4s - loss: 37406856.0000 - val_loss: 42778348.0000 - 4s/epoch - 4ms/step\n",
      "Epoch 126/150\n",
      "1179/1179 - 5s - loss: 36879660.0000 - val_loss: 42790912.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 127/150\n",
      "1179/1179 - 6s - loss: 37089164.0000 - val_loss: 43111164.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 128/150\n",
      "1179/1179 - 5s - loss: 36870096.0000 - val_loss: 40300452.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 129/150\n",
      "1179/1179 - 6s - loss: 36811536.0000 - val_loss: 41371732.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 130/150\n",
      "1179/1179 - 6s - loss: 37297096.0000 - val_loss: 45379660.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 131/150\n",
      "1179/1179 - 6s - loss: 38304076.0000 - val_loss: 41155956.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 132/150\n",
      "1179/1179 - 6s - loss: 36888856.0000 - val_loss: 41404992.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 133/150\n",
      "1179/1179 - 5s - loss: 36784456.0000 - val_loss: 41075000.0000 - 5s/epoch - 5ms/step\n",
      "Epoch 134/150\n",
      "1179/1179 - 6s - loss: 36688200.0000 - val_loss: 40459064.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 135/150\n",
      "1179/1179 - 5s - loss: 37135536.0000 - val_loss: 40196952.0000 - 5s/epoch - 5ms/step\n",
      "Epoch 136/150\n",
      "1179/1179 - 5s - loss: 37119412.0000 - val_loss: 40814876.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 137/150\n",
      "1179/1179 - 6s - loss: 37182232.0000 - val_loss: 41264820.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 138/150\n",
      "1179/1179 - 6s - loss: 36895216.0000 - val_loss: 43625744.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 139/150\n",
      "1179/1179 - 5s - loss: 37474728.0000 - val_loss: 41618112.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 140/150\n",
      "1179/1179 - 6s - loss: 37051556.0000 - val_loss: 42605188.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 141/150\n",
      "1179/1179 - 5s - loss: 36847496.0000 - val_loss: 45297496.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 142/150\n",
      "1179/1179 - 6s - loss: 37075908.0000 - val_loss: 42469556.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 143/150\n",
      "1179/1179 - 6s - loss: 36798344.0000 - val_loss: 41619292.0000 - 6s/epoch - 5ms/step\n",
      "Epoch 144/150\n",
      "1179/1179 - 5s - loss: 36528368.0000 - val_loss: 41102320.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 145/150\n",
      "1179/1179 - 5s - loss: 36732444.0000 - val_loss: 44788604.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 146/150\n",
      "1179/1179 - 4s - loss: 36746300.0000 - val_loss: 41574952.0000 - 4s/epoch - 4ms/step\n",
      "Epoch 147/150\n",
      "1179/1179 - 5s - loss: 36561664.0000 - val_loss: 41829076.0000 - 5s/epoch - 4ms/step\n",
      "Epoch 148/150\n",
      "1179/1179 - 4s - loss: 36501796.0000 - val_loss: 41136476.0000 - 4s/epoch - 3ms/step\n",
      "Epoch 149/150\n",
      "1179/1179 - 4s - loss: 36762016.0000 - val_loss: 43348844.0000 - 4s/epoch - 4ms/step\n",
      "Epoch 150/150\n",
      "1179/1179 - 4s - loss: 37130092.0000 - val_loss: 40470176.0000 - 4s/epoch - 3ms/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mneural_net\u001b[39;00m \u001b[39mimport\u001b[39;00m ann_model, mse\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mKNN\u001b[39;00m \u001b[39mimport\u001b[39;00m knn_model\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m test_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39macs2015_census_tract_data.csv\u001b[39m\u001b[39m'\u001b[39m)            \n",
      "File \u001b[1;32mc:\\Users\\LOWRYEC17\\OneDrive - Grove City College\\Documents\\MLProject\\KNN.py:109\u001b[0m\n\u001b[0;32m    105\u001b[0m knn_model\u001b[39m=\u001b[39m  KNeighborsRegressor(\u001b[39m8\u001b[39m),\n\u001b[0;32m    108\u001b[0m start \u001b[39m=\u001b[39m time()\n\u001b[1;32m--> 109\u001b[0m knn_model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m    110\u001b[0m train_time \u001b[39m=\u001b[39m time() \u001b[39m-\u001b[39m start\n\u001b[0;32m    111\u001b[0m start \u001b[39m=\u001b[39m time()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "from neural_net import ann_model, mse\n",
    "from KNN import knn_model\n",
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_csv('acs2015_census_tract_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, knn_weight, ann_weight, bayes_weight, logreg_weight) -> None:\n",
    "        self.knn_weight = knn_weight\n",
    "        self.ann_weight = ann_weight\n",
    "        self.bayes_weight = bayes_weight\n",
    "        self.logreg_weight = logreg_weight\n",
    "        assert(abs(1 - (knn_weight + ann_weight + bayes_weight + logreg_weight)) < 1e-3)\n",
    "        self.knn = knn_model\n",
    "        self.ann = ann_model\n",
    "        #self.bayes = bayes_model\n",
    "        #self.logreg = logreg_model\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.knn.predict(x)*self.knn_weight + self.ann.predict(x)*self.ann_weight # + self.bayes_model.predict(x)*self.bayes_weight + self.logreg.predict(x)*self.logreg_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m _model \u001b[39m=\u001b[39m Model(ann_weight\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, knn_weight\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)   \n\u001b[0;32m      2\u001b[0m mse(_model\u001b[39m.\u001b[39mpredict(test_df\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mIncomePerCap\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mIncome\u001b[39m\u001b[39m'\u001b[39m])))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Model' is not defined"
     ]
    }
   ],
   "source": [
    "_model = Model(ann_weight=0.5, knn_weight=0.5)   \n",
    "mse(_model.predict(test_df.drop(columns=['IncomePerCap','Income'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
